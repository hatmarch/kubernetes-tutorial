= Taints and Affinity
include::_attributes.adoc[]

So far, when we deployed any Pod in the Kubernetes cluster, it was run on any node that met the requirements (ie memory requirements, CPU requirements, ...)

However, in Kubernetes there are two concepts that allow you to further configure the scheduler, so that Pods are assigned to Nodes following some business criteria.

== Preparation

include::https://raw.githubusercontent.com/redhat-developer-demos/rhd-tutorial-common/master/minikube-multinode.adoc[]

== Taints

A Taint is applied to a Kubernetes Node that signals the scheduler to avoid or not schedule certain Pods.

A Toleration is applied to a Pod definition and provides an exception to the taint.

Let's describe the current nodes, in this case as an OpenShift cluster is used, you can see several nodes:

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl describe nodes | egrep "Name:|Taints:"
----

[.console-output]
[source,bash]
----
Name:               ip-10-0-136-107.eu-central-1.compute.internal
Taints:             node-role.kubernetes.io/master:NoSchedule
Name:               ip-10-0-140-186.eu-central-1.compute.internal
Taints:             <none>
Name:               ip-10-0-141-128.eu-central-1.compute.internal
Taints:             <none>
Name:               ip-10-0-146-109.eu-central-1.compute.internal
Taints:             <none>
Name:               ip-10-0-150-226.eu-central-1.compute.internal
Taints:             <none>
----

[NOTE]
====
Notice that in this case, the `master` node contains a taint which blocks your application Pods from being scheduled there.
====

Let's add a taint to all nodes:

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl taint nodes --all=true color=blue:NoSchedule
----

[.console-output]
[source,bash]
----
node/ip-10-0-136-107.eu-central-1.compute.internal tainted
node/ip-10-0-140-186.eu-central-1.compute.internal tainted
node/ip-10-0-141-128.eu-central-1.compute.internal tainted
node/ip-10-0-146-109.eu-central-1.compute.internal tainted
node/ip-10-0-150-226.eu-central-1.compute.internal tainted
node/ip-10-0-155-122.eu-central-1.compute.internal tainted
node/ip-10-0-162-206.eu-central-1.compute.internal tainted
node/ip-10-0-168-102.eu-central-1.compute.internal tainted
node/ip-10-0-175-64.eu-central-1.compute.internal tainted
----

The color=blue is simply a key=value pair to identify the taint and NoSchedule is the specific effect for pods that can't "tolerate" the taint.  In other words, if a pod does not tolerate "color=blue" then the effect will be "NoSchedule"

So let's try this out.  We'll deploy a new pod that doesn't have any particular tolerations.  First, to be able to observe what's going on, let's open another terminal (*Terminal 2*) and watch what happens to the pods as we change taints on the nodes.

[tabs]
====
Terminal 2::
+
--

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
watch -n 1 -- kubectl get pods -o wide #<.>
----
<.> the `-o wide` option allows us to see the node that the pod is schedule to

--
====

Now deploy a new pod in the main terminal

[tabs]
====
Terminal 1::
+
--
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl apply -f apps/kubefiles/myboot-deployment.yml
----
--
====

You'll see the output in the other terminal change

[tabs]
====
Terminal 2::
+
--
[.console-output]
[source,bash,subs="+quotes"]
----
NAME                      READY   STATUS    RESTARTS   AGE     IP       NODE     NOMINATED NODE   READINESS GATES
myboot-7cbfbd9b89-hqx6h   0/1     #Pending#   0          4m12s   <none>   <none>   <none>           <none>
----
--
====

The pod will remain in `Pending` status as it has no schedulable Node available.

We can get more insight into this by entering the following

[tabs]
====
Terminal 1 - Minikube::
+
--
// include untagged regions and any regions tagged with minikube
// See: https://docs.asciidoctor.org/asciidoc/latest/directives/include-tagged-regions/#tagging-regions
include::partial$taint-remove-taint.adoc[tags=**;!*;minikube]

--
Terminal 1 - OpenShift::
+
--
// Include all untagged regions and any regions tagged with openshift
// See: https://docs.asciidoctor.org/asciidoc/latest/directives/include-tagged-regions/#tagging-regions
include::partial$taint-remove-taint.adoc[tags=**;!*;openshift]

--
====

Now in *Terminal 2* you should see the Pending pod scheduled to the newly untained node.  

[tabs]
====
Terminal 2::
+
--
[.console-output]
[source,bash,subs="+quotes"]
----
NAME                      READY   STATUS              RESTARTS   AGE   IP       NODE            NOMINATED NODE   READINES
S GATES
myboot-7cbfbd9b89-hqx6h   0/1     #ContainerCreating#   0          20m   <none>   #devnation-m02#   <none>           <none>
----
--
====

Finally, let's take a quick look at the taint status on all the nodes.  

[tabs]
====
Terminal 1::
+
--
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl describe nodes | egrep "Name:|Taints:"
----

[.console-output]
[source,bash]
----
Name:               ip-10-0-136-107.eu-central-1.compute.internal
Taints:             node-role.kubernetes.io/master:NoSchedule
Name:               ip-10-0-140-186.eu-central-1.compute.internal
Taints:             <none>
Name:               ip-10-0-141-128.eu-central-1.compute.internal
Taints:             color=blue:NoSchedule
Name:               ip-10-0-146-109.eu-central-1.compute.internal
Taints:             color=blue:NoSchedule
----

--
====

=== Restore Taint

Add the taint back to the node (or in this case all nodes): 

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl taint nodes --all=true color=blue:NoSchedule --overwrite
----

[TIP]
====
Setting the taint on all nodes is a bit sloppy.  If you'd like you can get the same effect a bit more elegantly by setting the taint only on the node from which it was removed.  For example:

----
kubectl taint node ip-10-0-140-186.eu-central-1.compute.internal color=blue:NoSchedule
----
====

Take a look and notice that the pod is still running despite the change in taint (this is due to scheduling being a one time activity in the lifecycle of a pod)

[tabs]
====
Terminal 2::
+
--
[.console-output]
[source,bash,subs="+macros,+attributes,+quotes"]
----
NAME                      READY   STATUS    RESTARTS   AGE   IP           NODE            NOMIN
ATED NODE   READINESS GATES
myboot-7cbfbd9b89-bzhxw   1/1     #Running#   0          18m   172.17.0.2   devnation-m02   <none>           <none>
----

--
====


=== Clean Up

Undeploy the myboot deployment and add again the taint to the node:

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl delete -f apps/kubefiles/myboot-deployment.yml
----

== Tolerations

Let's create a Pod but containing a toleration, so it can be scheduled to a tainted node.

[source, yaml]
----
spec:
  tolerations:
  - key: "color"
    operator: "Equal"
    value: "blue"
    effect: "NoSchedule"
  containers:
  - name: myboot
    image: quay.io/rhdevelopers/myboot:v1
----

[tabs]
====
Terminal 1::
+
--
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl apply -f apps/kubefiles/myboot-toleration.yaml
----
--
====

And then we should see before too long in our watch window our pod get scheduled and advance to the run state

[tabs]
====
Terminal 2::
+
--
[.console-output]
[source,bash,subs="+quotes"]
----
NAME                      READY   STATUS    RESTARTS   AGE
myboot-84b457458b-mbf9r   1/1     #Running#   0          3m18s
----
--
====

Now, although all nodes contain a taint, the Pod is scheduled and run as we defined a tolerance against color=blue taint.

=== Clean Up

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl delete -f apps/kubefiles/myboot-toleration.yaml
----

== `NoExecution` Taint

So far, you've seen the `NoSchedule` taint effect which means that newly created Pods will not be scheduled there unless they have an overriding toleration.
But notice that if we add this taint to a node that already has running/scheduled Pods, this taint will not terminate them.

Let's change that by using `NoExecution` effect. 

First of all, let's remove all previous taints.

[tabs]
====
Terminal 1::
+
--
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl taint nodes --all=true color=blue:NoSchedule-
----
--
====


Then deploy a service:

[tabs]
====
Terminal 1::
+
--
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl apply -f apps/kubefiles/myboot-deployment.yml
----
--
====

We should see the following in the watch

[tabs]
====
Terminal 2::
+
--
[.console-output]
[source,bash]
----
NAME                      READY   STATUS    RESTARTS   AGE   IP           NODE            NOMINATED NODE   READINESS GATES
myboot-7cbfbd9b89-wpddg   1/1     Running   0          47s   172.17.0.2   devnation-m02   <none>           <none>
----

--
====

Now let's taint find the node the pod is running on

[tabs]
====
Terminal 1::
+
--
[.console-input]
[source,bash,subs="+macros"]
----
NODE=$(kubectl get pod -o jsonpath='{.items[0].spec.nodeName}') #<.>
echo ${NODE}

----
<.> the `.items[0]` is because we're asking for all pods, but we know our list will contain only one element

[.console-output]
[source,bash]
----
"ip-10-0-146-109.eu-central-1.compute.internal"
----
--
====


[tabs]
====
Terminal 1::
+
--
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl taint node pass:[${NODE}] color=blue:NoExecute
----
--
====

As soon as we do this, we should be able to watch this "rescheduling" occur in the Terminal 2 watch

[tabs]
====
Terminal 2::
+
--

[.console-output]
[source,bash,subs="+quotes"]
----
NAME                      READY   STATUS              RESTARTS   AGE   IP           NODE     NOMINATED NODE   READINESS GATES
myboot-7cbfbd9b89-5t24z   0/1     #ContainerCreating#   0          16s   <none>       devnation     <none>           <none>
myboot-7cbfbd9b89-wpddg   1/1     #Terminating#         0          65m   172.17.0.2   devnation-m02   <none>           <none> 
----

--
====

[NOTE]
====
If you have more nodes available then the Pod is terminated and deployed onto another node, if it is not the case, then the Pod will remain in `Pending` status.
====

=== Clean Up

[tabs]
====
Terminal 1::
+
--
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl delete -f apps/kubefiles/myboot-deployment.yml
----
--
====

And remove the NoExecute taint 

[tabs]
====
Terminal 1::
+
--
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl taint node pass:[${NODE}] color=blue:NoExecute-
----
--
====

== Affinity & Anti-Affinity

There is another way of changing where Pods are scheduled using Node/Pod Affinity and Anti-affinity.
You can create rules that not only ban where Pods can run but also to favor where they should be run.

In addition to creating affinities between Pods and Nodes, you can also create affinities between Pods.  You can decide that a group of Pods should be always be deployed together on the same node(s).
Reasons such as significant network communication between Pods and you want to avoid external network calls or perhaps shared storage devices.

=== Node Affinity

Let's deploy a new pod with a node affinity:

[source, yaml]
----
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: color
            operator: In
            values:
            - blue
      containers:
      - name: myboot
        image: quay.io/rhdevelopers/myboot:v1
----

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl apply -f apps/kubefiles/myboot-node-affinity.yml

kubectl get pods
----

[.console-output]
[source,bash]
----
NAME                           READY   STATUS    RESTARTS   AGE
myboot-54d788fdc8-f6wks        0/1     Pending   0          13s
----

Let's create a label on a node matching the affinity expression:

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl get nodes
----

[.console-output]
[source,bash]
----
NAME                                            STATUS   ROLES    AGE   VERSION
ip-10-0-136-107.eu-central-1.compute.internal   Ready    master   26h   v1.16.2
ip-10-0-140-186.eu-central-1.compute.internal   Ready    worker   26h   v1.16.2
ip-10-0-141-128.eu-central-1.compute.internal   Ready    worker   25h   v1.16.2
ip-10-0-146-109.eu-central-1.compute.internal   Ready    worker   25h   v1.16.2
ip-10-0-150-226.eu-central-1.compute.internal   Ready    worker   26h   v1.16.2
ip-10-0-155-122.eu-central-1.compute.internal   Ready    master   26h   v1.16.2
ip-10-0-162-206.eu-central-1.compute.internal   Ready    worker   26h   v1.16.2
ip-10-0-168-102.eu-central-1.compute.internal   Ready    master   26h   v1.16.2
ip-10-0-175-64.eu-central-1.compute.internal    Ready    worker   25h   v1.16.2
----

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl label nodes ip-10-0-175-64.eu-central-1.compute.internal color=blue
----

[.console-output]
[source,bash]
----
node/ip-10-0-175-64.eu-central-1.compute.internal labeled
----

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl get pods
----

[.console-output]
[source,bash]
----
NAME                          READY   STATUS    RESTARTS   AGE
myboot-54d788fdc8-f6wks       1/1     Running   0          7m57s
----

Let's delete the label from the node:

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl label nodes ip-10-0-175-64.eu-central-1.compute.internal color-

kubectl get pods
----

[.console-output]
[source,bash]
----
NAME                         READY   STATUS    RESTARTS   AGE
myboot-54d788fdc8-f6wks      1/1     Running   0          7m57s
----

As with taints, the rule is set during the scheduling phase, therefore, the Pod is not removed.

This is an example of a _hard_ rule, if the Kubernetes scheduler does not find any node with the required label then the Pod reminds in _Pending_ state.
There is also a way to create a _soft_ rule, where the Kubernetes scheduler attempts to match the rules but if it can not then the Pod is scheduled to any node.  In the example below, you can see the use of the word _preferred_ vs _required_.

[source, yaml]
----
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        preference:
          matchExpressions:
          - key: color
            operator: In
            values:
            - blue
----

==== Clean Up

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl delete -f apps/kubefiles/myboot-node-affinity.yml
----

=== Pod Affinity/Anti-Affinity

Let's deploy a new pod with a Pod Affinity:

[source, yaml]
----
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - topologyKey: kubernetes.io/hostname # <1>
        labelSelector: 
          matchExpressions:
          - key: app
            operator: In
            values:
            - myboot # <2>
  containers:
----
<1> The node label key. If two nodes are labeled with this key and have identical values, the scheduler treats both nodes as being in the same topology. In this case, `hostname` is a label that is different for each node.
<2> The affinity is with Pods labeled with `app=myboot`.

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl apply -f apps/kubefiles/myboot-pod-affinity.yml

kubectl get pods
----

[.console-output]
[source,bash]
----
NAME                                                              READY   STATUS    RESTARTS   AGE
myboot2-784bc58c8d-j2l74                                          0/1     Pending   0          19s
----

The `myboot2` Pod is pending as couldn't find any Pod matching the affinity rule.
Let's deploy `myboot` application labeled with `app=myboot`.

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl apply -f apps/kubefiles/myboot-deployment.yml

kubectl get pods
----

[.console-output]
[source,bash]
----
NAME                                                              READY   STATUS    RESTARTS   AGE
myboot-7f889dd6d-tr7gr                                            1/1     Running   0          3m27s
myboot2-64566b697b-snm7p                                          1/1     Running   0          18s
----

Now both applications are running in the same node:

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl get pod myboot-7f889dd6d-tr7gr -o json | jq '.spec.nodeName'
----

[.console-output]
[source,bash]
----
"ip-10-0-146-109.eu-central-1.compute.internal"
----

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl get pod myboot2-64566b697b-snm7p -o json | jq '.spec.nodeName'
----

[.console-output]
[source,bash]
----
"ip-10-0-146-109.eu-central-1.compute.internal"
----

What you've seen here is a _hard_ rule, you can use a "soft" rules as well in Pod Affinity.

[source, yaml]
----
spec:
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 1
        podAffinityTerm:
          topologyKey: kubernetes.io/hostname 
          labelSelector:
            matchExpressions:  
            - key: app
              operator: In
              values:
              - myboot   
----

Anti-affinity is used to insure that two Pods do NOT run together on the same node.

[source, yaml]
----
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - topologyKey: kubernetes.io/hostname
        labelSelector: 
          matchExpressions:
          - key: app
            operator: In
            values:
            - myboot
----

Deploy a myboot3 with an anti-affinity rule

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl apply -f apps/kubefiles/myboot-pod-antiaffinity.yaml
----

And then use the `kubectl get pods -o wide` command to see which pods land on which nodes.

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl get pods -o wide
----

[.console-output]
[source,bash]
----
NAME                       READY   STATUS    RESTARTS   AGE    IP          NODE
myboot-7f889dd6d-tr7gz     1/1     Running   0          4m27s  10.88.0.9   devnation-m02
myboot2-64566b697b-snm7p   1/1     Running   0          48s    10.88.0.10  devnation-m02 
myboot3-78656b637r-suy1t   1/1     Running   0          1s     172.17.0.2  devnation
----

`myboot3` Pod is deployed in a different node than the `myboot` Pod

==== Clean Up

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl delete -f apps/kubefiles/myboot-pod-affinity.yml
kubectl delete -f apps/kubefiles/myboot-pod-antiaffinity.yml
kubectl delete -f apps/kubefiles/myboot-deployment.yml
----